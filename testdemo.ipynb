{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import caffe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (234L, 238L, 3L)\n"
     ]
    }
   ],
   "source": [
    "image_path = './test/1.jpg'\n",
    "im = cv2.imread(image_path)\n",
    "assert im is not None, 'Image is empty'\n",
    "im_bk = im.copy()\n",
    "\n",
    "im = im.astype(np.float32)\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "im = np.transpose(im, (1,0,2)) #Rotate image.\n",
    "image_height, image_width, num_channels = im.shape\n",
    "print('Image shape:', im.shape)\n",
    "\n",
    "assert num_channels == 3, 'Error: only support RGB image.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FAGE_SIZE = 24. # Minimum face size\n",
    "MIN_INPUT_SIZE = 12. # Minimum input size\n",
    "m = MIN_INPUT_SIZE / MIN_FAGE_SIZE\n",
    "\n",
    "min_size = min(image_height, image_width)\n",
    "min_size = min_size * m\n",
    "\n",
    "scales = []\n",
    "counter = 0\n",
    "FACTOR = 0.709\n",
    "\n",
    "while min_size >= MIN_INPUT_SIZE:\n",
    "    scales.append(m * FACTOR**counter)\n",
    "    min_size = min_size * FACTOR\n",
    "    counter = counter + 1\n",
    "\n",
    "# load models\n",
    "prototxt = ['./model/' + x + '.prototxt' for x in ['det1', 'det2', 'det3']]\n",
    "weights = ['./model/' + x + '.caffemodel' for x in ['det1', 'det2', 'det3']]\n",
    "PNet = caffe.Net(prototxt[0], weights[0], caffe.TEST)\n",
    "RNet = caffe.Net(prototxt[1], weights[1], caffe.TEST)\n",
    "ONet = caffe.Net(prototxt[2], weights[2], caffe.TEST)\n",
    "# Threshold for each stage.\n",
    "THRESHOLD = [0.6, 0.7, 0.7]\n",
    "\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_and_show(im, bboxes, points=None):\n",
    "    '''Draw bboxes and points on image, and show.\n",
    "\n",
    "    Args:\n",
    "      im: image to draw on.\n",
    "      bboxes: (tensor) bouding boxes sized [N,4].\n",
    "      points: (tensor) landmark points sized [N,10],\n",
    "        coordinates arranged as [x,x,x,x,x,y,y,y,y,y].\n",
    "    '''\n",
    "    print('Drawing..')\n",
    "\n",
    "    num_boxes = bboxes.shape[0]\n",
    "    for i in range(num_boxes):\n",
    "        box = bboxes[i]\n",
    "        x1 = int(box[0])\n",
    "        y1 = int(box[1])\n",
    "        x2 = int(box[2])\n",
    "        y2 = int(box[3])\n",
    "        print('Rect:', y1, x1, y2, x2)\n",
    "        # As im is rotated, so need to swap x and y.\n",
    "        cv2.rectangle(im, (y1,x1), (y2,x2), (0,255,255), 2)\n",
    "\n",
    "        if points.size:\n",
    "            p = points[i]\n",
    "            for i in range(5):\n",
    "                x = int(p[i])\n",
    "                y = int(p[i+5])\n",
    "                # Again, swap x and y.\n",
    "                cv2.circle(im, (y,x), 1, (0,0,255), 2)\n",
    "\n",
    "    cv2.imshow('result', im)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(bboxes, threshold=0.5, mode='union'):\n",
    "    '''Non max suppression.\n",
    "\n",
    "    Args:\n",
    "      bboxes: (tensor) bounding boxes and scores sized [N, 5].\n",
    "      threshold: (float) overlap threshold.\n",
    "      mode: (str) 'union' or 'min'.\n",
    "\n",
    "    Returns:\n",
    "      Bboxes after nms.\n",
    "      Picked indices.\n",
    "\n",
    "    Ref:\n",
    "      https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/nms/py_cpu_nms.py\n",
    "    '''\n",
    "    x1 = bboxes[:,0]\n",
    "    y1 = bboxes[:,1]\n",
    "    x2 = bboxes[:,2]\n",
    "    y2 = bboxes[:,3]\n",
    "    scores = bboxes[:, 4]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "\n",
    "        inter = w * h\n",
    "        if mode == 'union':\n",
    "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        elif mode == 'min':\n",
    "            ovr = inter / np.minimum(areas[i], areas[order[1:]])\n",
    "        else:\n",
    "            raise TypeError('Unknown nms mode: %s.' % mode )\n",
    "\n",
    "        inds = np.where(ovr <= threshold)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return bboxes[keep], keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(bboxes, im_height, im_width):\n",
    "    '''Padding bouding boxes the edge of image, if it's too large.'''\n",
    "    bboxes[:,0] = np.maximum(0, bboxes[:,0])\n",
    "    bboxes[:,1] = np.maximum(0, bboxes[:,1])\n",
    "    bboxes[:,2] = np.maximum(im_width-1, bboxes[:,2])\n",
    "    bboxes[:,3] = np.maximum(im_height-1, bboxes[:,3])\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_to_square(bboxes):\n",
    "    '''Make bounding boxes square.'''\n",
    "    square_bbox = bboxes.copy()\n",
    "\n",
    "    w = bboxes[:,2] - bboxes[:,0] + 1\n",
    "    h = bboxes[:,3] - bboxes[:,1] + 1\n",
    "    max_side = np.maximum(h,w)\n",
    "\n",
    "    square_bbox[:,0] = bboxes[:,0] + (w - max_side) * 0.5\n",
    "    square_bbox[:,1] = bboxes[:,1] + (h - max_side) * 0.5\n",
    "    square_bbox[:,2] = square_bbox[:,0] + max_side - 1\n",
    "    square_bbox[:,3] = square_bbox[:,1] + max_side - 1\n",
    "\n",
    "    return square_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_regression(bboxes):\n",
    "    '''Bounding box regression.\n",
    "\n",
    "    Args:\n",
    "      bboxes: (tensor) bounding boxes sized [N,9], containing:\n",
    "        x1, y1, x2, y2, score, regy1, regx1, regy2, regx2.\n",
    "\n",
    "    Return:\n",
    "      Regressed bounding boxes sized [N,5].\n",
    "    '''\n",
    "    bbw = bboxes[:,2] - bboxes[:,0] + 1\n",
    "    bbh = bboxes[:,3] - bboxes[:,1] + 1\n",
    "\n",
    "    x1 = bboxes[:,0]\n",
    "    y1 = bboxes[:,1]\n",
    "    x2 = bboxes[:,2]\n",
    "    y2 = bboxes[:,3]\n",
    "\n",
    "    scores = bboxes[:,4]\n",
    "\n",
    "    # Note the sequence.\n",
    "    rgy1 = bboxes[:,5]\n",
    "    rgx1 = bboxes[:,6]\n",
    "    rgy2 = bboxes[:,7]\n",
    "    rgx2 = bboxes[:,8]\n",
    "\n",
    "    ret = np.vstack([x1 + rgx1 * bbw,\n",
    "                     y1 + rgy1 * bbh,\n",
    "                     x2 + rgx2 * bbw,\n",
    "                     y2 + rgy2 * bbh,\n",
    "                     scores])\n",
    "    return ret.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pnet_boxes(outputs, scale, threshold):\n",
    "    '''Generate bouding boxes from PNet outputs.\n",
    "\n",
    "    Args:\n",
    "      outputs: (dict) PNet outputs.\n",
    "      scale: (float) image scale ration.\n",
    "      threshold: (float) confidence threshold.\n",
    "\n",
    "    Returns:\n",
    "      A tensor representing generated bounding boxes sized [N,9].\n",
    "    '''\n",
    "    confidence = outputs['prob1'][0][1]  # [H,W]\n",
    "    regression = outputs['conv4-2'][0]   # [4,H,W]\n",
    "\n",
    "    # Filter out confidence > threshold.\n",
    "    # Note:\n",
    "    #   y is the row-index.\n",
    "    #   x is the col-index.\n",
    "    y, x = np.where(confidence > threshold)\n",
    "\n",
    "    # Get regression outputs.\n",
    "    reg_y1, reg_x1, reg_y2, reg_x2 = [regression[i,y,x] for i in range(4)]\n",
    "    reg = np.array([reg_x1, reg_y1, reg_x2, reg_y2])\n",
    "\n",
    "    # Get scores.\n",
    "    scores = confidence[y,x]  # [N,]\n",
    "\n",
    "    # Get face rects.\n",
    "    stride = 2\n",
    "    cell_size = 12\n",
    "\n",
    "    x1 = np.round((stride*x+1) / scale)\n",
    "    y1 = np.round((stride*y+1) / scale)\n",
    "    x2 = np.round((stride*x+1 + cell_size-1) / scale)\n",
    "    y2 = np.round((stride*y+1 + cell_size-1) / scale)\n",
    "    rect = np.array([x1, y1, x2, y2])\n",
    "\n",
    "    bbox = np.vstack([rect, scores, reg])  # [9,N]\n",
    "    return bbox.T  # [N,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnet_boxes(bboxes, outputs, threshold):\n",
    "    '''Generate bounding boxes from RNet outputs.\n",
    "\n",
    "    Args:\n",
    "      bboxes: (tensor) PNet bouding boxes sized [N,5].\n",
    "      outputs: (dict) RNet outputs.\n",
    "      threshold: (float) confidence threshold.\n",
    "\n",
    "    Returns:\n",
    "      A tensor representing generated bounding boxes sized [N,9].\n",
    "    '''\n",
    "    confidence = outputs['prob1'][:,1]\n",
    "    regression = outputs['conv5-2']\n",
    "\n",
    "    indices = np.where(confidence > threshold)\n",
    "    rects = bboxes[indices][:,0:4]  # [N,4]\n",
    "    scores = confidence[indices]    # [N,]\n",
    "    scores = scores.reshape(-1,1)   # [N,1]\n",
    "    regs = regression[indices]      # [N,4]\n",
    "\n",
    "    return np.hstack([rects, scores, regs])  # [N,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onet_boxes(bboxes, outputs, threshold):\n",
    "    '''Generate bounding boxes and points from ONet outputs.\n",
    "\n",
    "    Args:\n",
    "      bboxes: (tensor) RNet bounding boxes sized [N,5].\n",
    "      outputs: (dict) ONet outputs.\n",
    "      threshold: (float) confidence threshold.\n",
    "\n",
    "    Returns:\n",
    "      A tensor representing generated bounding boxes sized [N,9].\n",
    "      A tensor representing points sized [N,10].\n",
    "    '''\n",
    "    confidence = outputs['prob1'][:,1]\n",
    "    regression = outputs['conv6-2']\n",
    "    points = outputs['conv6-3']\n",
    "\n",
    "    indices = np.where(confidence > threshold)\n",
    "\n",
    "    rects = bboxes[indices][:,0:4]\n",
    "    scores = confidence[indices]\n",
    "    scores = scores.reshape(-1,1)\n",
    "    regs = regression[indices]\n",
    "\n",
    "    points = points[indices]   # Note `y` is in the front.\n",
    "    points_y = points[:,0:5]   # [N,5]\n",
    "    points_x = points[:,5:10]  # [N,5]\n",
    "\n",
    "    w = rects[:,2] - rects[:,0] + 1\n",
    "    h = rects[:,3] - rects[:,1] + 1\n",
    "\n",
    "    x1 = rects[:,0]\n",
    "    y1 = rects[:,1]\n",
    "\n",
    "    points_x = points_x * w.reshape(-1,1) + x1.reshape(-1,1)\n",
    "    points_y = points_y * h.reshape(-1,1) + y1.reshape(-1,1)\n",
    "\n",
    "    # We move `x` ahead, points=[x,x,x,x,x,y,y,y,y,y].\n",
    "    return np.hstack([rects, scores, regs]), np.hstack([points_x, points_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_from_bboxes(im, bboxes, size):\n",
    "    '''Get network inputs based on generated bounding boxes.\n",
    "\n",
    "    Args:\n",
    "      im: (image) rotated original image.\n",
    "      bboxes: (tensor) regressed bounding boxes sized [N,5].\n",
    "      size: (int) expected input size.\n",
    "\n",
    "    Returns:\n",
    "      A tensor sized [N, 3, size, size].\n",
    "    '''\n",
    "    num_boxes = bboxes.shape[0]\n",
    "    inputs = np.zeros((num_boxes, size, size, 3), dtype=np.float32)\n",
    "    for i in range(num_boxes):\n",
    "        x1 = int(bboxes[i,0])\n",
    "        y1 = int(bboxes[i,1])\n",
    "        x2 = int(bboxes[i,2])\n",
    "        y2 = int(bboxes[i,3])\n",
    "\n",
    "        im_crop = im[y1:y2+1, x1:x2+1, :]\n",
    "        inputs[i] = cv2.resize(im_crop, (size,size))\n",
    "\n",
    "    # [N,H,W,C] -> [N,C,H,W] to meet the Caffe needs.\n",
    "    inputs = np.transpose(inputs, (0,3,1,2))\n",
    "\n",
    "    # Zero mean and normalization.\n",
    "    inputs = (inputs - 127.5) * 0.0078125\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize to: (117L, 119L, 3L)\n",
      "Resize to: (83L, 85L, 3L)\n",
      "Resize to: (59L, 60L, 3L)\n",
      "Resize to: (42L, 43L, 3L)\n",
      "Resize to: (30L, 31L, 3L)\n",
      "Resize to: (21L, 22L, 3L)\n",
      "Resize to: (15L, 16L, 3L)\n",
      "After PNet bboxes shape:  (37L, 5L)\n"
     ]
    }
   ],
   "source": [
    "# First stage.\n",
    "#\n",
    "total_boxes = []  # Bounding boxes of all scales.\n",
    "for scale in scales:\n",
    "    hs = int(math.ceil(image_height*scale))\n",
    "    ws = int(math.ceil(image_width*scale))\n",
    "\n",
    "    im_resized = cv2.resize(im, (ws,hs), interpolation=cv2.INTER_AREA)\n",
    "    print('Resize to:', im_resized.shape)\n",
    "\n",
    "    # H,W,C -> C,H,W\n",
    "    im_resized = np.transpose(im_resized, (2,0,1))\n",
    "\n",
    "    # Zero mean and normalization.\n",
    "    im_resized = (im_resized - 127.5) * 0.0078125\n",
    "\n",
    "    # Reshape input layer.\n",
    "    PNet.blobs['data'].reshape(1, 3, hs, ws)\n",
    "    PNet.blobs['data'].data[...] = im_resized\n",
    "    outputs = PNet.forward()\n",
    "\n",
    "    bboxes = get_pnet_boxes(outputs, scale, THRESHOLD[0])\n",
    "    bboxes,_ = non_max_suppression(bboxes, 0.5)\n",
    "\n",
    "    total_boxes.append(bboxes)\n",
    "\n",
    "total_boxes = np.vstack(total_boxes)\n",
    "\n",
    "bboxes,_ = non_max_suppression(total_boxes, 0.7)\n",
    "bboxes = bbox_regression(total_boxes)\n",
    "\n",
    "bboxes = bbox_to_square(bboxes)\n",
    "bboxes = padding(bboxes, image_height, image_width)\n",
    "\n",
    "print('After PNet bboxes shape: ', bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After RNet bboxes shape:  (3L, 5L)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Second stage.\n",
    "#\n",
    "inputs = get_inputs_from_bboxes(im, bboxes, 24)\n",
    "N,C,H,W = inputs.shape\n",
    "\n",
    "RNet.blobs['data'].reshape(N,3,H,W)\n",
    "RNet.blobs['data'].data[...] = inputs\n",
    "outputs = RNet.forward()\n",
    "\n",
    "bboxes = get_rnet_boxes(bboxes, outputs, THRESHOLD[1])\n",
    "\n",
    "bboxes,_ = non_max_suppression(bboxes, 0.7)\n",
    "bboxes = bbox_regression(bboxes)\n",
    "bboxes = bbox_to_square(bboxes)\n",
    "bboxes = padding(bboxes, image_height, image_width)\n",
    "\n",
    "print('After RNet bboxes shape: ', bboxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ONet bboxes shape:  (1L, 5L) \n",
      "\n",
      "[[  0.          20.07420855 237.         233.           1.        ]]\n",
      "Total time: 317.808s\n",
      "\n",
      "Drawing..\n",
      "Rect: 20 0 233 237\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Third stage.\n",
    "#\n",
    "inputs = get_inputs_from_bboxes(im, bboxes, 48)\n",
    "N,C,H,W = inputs.shape\n",
    "\n",
    "ONet.blobs['data'].reshape(N,3,H,W)\n",
    "ONet.blobs['data'].data[...] = inputs\n",
    "outputs = ONet.forward()\n",
    "\n",
    "bboxes, points = get_onet_boxes(bboxes, outputs, THRESHOLD[2])\n",
    "bboxes = bbox_regression(bboxes)\n",
    "\n",
    "bboxes, picked_indices = non_max_suppression(bboxes, 0.7, 'min')\n",
    "points = points[picked_indices]\n",
    "bboxes = padding(bboxes, image_height, image_width)\n",
    "\n",
    "print('After ONet bboxes shape: ', bboxes.shape, '\\n')\n",
    "print(bboxes)\n",
    "assert bboxes.shape[0] != 0, 'no face'\n",
    "\n",
    "t2 = time.time()\n",
    "print('Total time: %.3fs\\n' % (t2-t1))\n",
    "\n",
    "draw_and_show(im_bk, bboxes, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
